{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can a machine identify a bee as a honey bee or a bumble bee? These bees have different behaviors and appearances, but given the variety of backgrounds, positions, and image resolutions, it can be a challenge for machines to tell them apart.\n",
    "\n",
    "Being able to identify bee species from images is a task that ultimately would allow researchers to more quickly and effectively collect field data. Pollinating bees have critical roles in both ecology and agriculture, and diseases like colony collapse disorder threaten these species. Identifying different species of bees in the wild means that we can better understand the prevalence and growth of these important insects.\n",
    "\n",
    "This notebook walks through building a simple deep learning model that can automatically detect honey bees and bumble bees and then loads a pre-trained model for evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from pathlib import Path\n",
    "from skimage import io\n",
    "from PIL import Image\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import tensorflow as tf\n",
    "# import keras library\n",
    "import keras\n",
    "from tensorflow import keras\n",
    "\n",
    "# import Sequential from the keras models module\n",
    "from keras.models import Sequential\n",
    "from keras import optimizers\n",
    "from keras.layers import BatchNormalization\n",
    "\n",
    "# import Dense, Dropout, Flatten, Conv2D, MaxPooling2D from the keras layers module\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have all of our imports ready, it is time to look at the labels for our data. We will load our labels.csv file into a DataFrame called labels, where the index column is the image number, the path column contains links to the images, is_bee column tells us wheter it's bee or not(1 is bee, 0 is wasp), and label column also difens bee or wasp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    path  is_bee label\n",
      "0      bee1\\10007154554_026417cfd0_n.jpg       1   bee\n",
      "1      bee1\\10024864894_6dc54d4b34_n.jpg       1   bee\n",
      "2      bee1\\10092043833_7306dfd1f0_n.jpg       1   bee\n",
      "3       bee1\\1011948979_fc3637e779_w.jpg       1   bee\n",
      "4      bee1\\10128235063_dca17db76c_n.jpg       1   bee\n",
      "...                                  ...     ...   ...\n",
      "4178   wasp1\\3542831662_efb4160ca9_m.jpg       0  wasp\n",
      "4179  wasp1\\35432436473_7068a1735d_m.jpg       0  wasp\n",
      "4180   wasp1\\3544475628_83c2f6c3bd_n.jpg       0  wasp\n",
      "4181   wasp1\\3548915632_44cc847833_w.jpg       0  wasp\n",
      "4182  wasp1\\35527909200_6d2c01fcf2_m.jpg       0  wasp\n",
      "\n",
      "[2000 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# load labels.csv from datasets folder using pandas\n",
    "\n",
    "labels = pd.read_csv('https://www.kaggle.com/datasets/jerzydziewierz/bee-vs-wasp', index_col=None)\n",
    "labels = labels[labels['photo_quality'] == 1] #quality ==1 meaning we are sure 100% what is on an image.\n",
    "\n",
    "# to keep only columns 'path', 'is_bee', 'label'\n",
    "labels = labels[['path', 'is_bee', 'label']]\n",
    "\n",
    "labels = labels[(labels['label'] == 'bee') | (labels['label'] == 'wasp')]\n",
    "labels.is_bee.value_counts() #0 - wasp, 1 - bee\n",
    "y = labels.is_bee\n",
    "\n",
    "# concate bees and wasps in 1 dataframe, include 1000 image of each genus\n",
    "def concat(labels):\n",
    "    labels_bee = labels[labels['label'] == 'bee'][:1000]\n",
    "    labels_wasp = labels[labels['label'] == 'wasp'][:1000]\n",
    "    labels_concat = pd.concat([labels_bee, labels_wasp], axis=0)\n",
    "    return labels_concat\n",
    "\n",
    "labels_concat = concat(labels)\n",
    "print(labels_concat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will import all images and preprocessed them - resize(also an option to convert images into grey scale) \n",
    "Once imported, we will stack the resulting arrays into a single matrix and assign it to X."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 50, 50, 3)\n",
      "(2000,)\n"
     ]
    }
   ],
   "source": [
    "image_paths = list(labels_concat.path)\n",
    "image_new_paths = []\n",
    "\n",
    "def process_image(path):\n",
    "    #Load the image with Image.open and create paths to save our images to\n",
    "    img = Image.open('\\\\bee_or_wasp\\\\kaggle_bee_vs_wasp\\\\{}'.format(path))\n",
    "    \n",
    "     # create paths to save files to\n",
    "    #bw_path = \"\\\\kaggle_bee_vs_wasp\\\\saved_images\\\\bw\\\\bw_{}.jpg\".format(path.stem) #grey scale images if you need to put 'em in b&w\n",
    "    rcz_path = \"\\\\kaggle_bee_vs_wasp\\\\saved_images\\\\rsz\\\\rsz_{}.jpg\".format(path.stem)\n",
    "    \n",
    "    #create bw images\n",
    "    #bw = img.convert(\"L\")\n",
    "    #bw.save(bw_path)\n",
    "    \n",
    "    #resize images and safe them to created path\n",
    "    rcz = img.resize((50, 50))\n",
    "    rcz.save(rcz_path)\n",
    "    \n",
    "    image_new_paths.append(rcz_path)\n",
    "    return image_new_paths\n",
    "    \n",
    "# for loop over image paths\n",
    "for img_path in image_paths:\n",
    "    process_image(Path(img_path))\n",
    "    \n",
    "labels_concat['rsz_path'] = image_new_paths\n",
    "\n",
    "#Â create empty list\n",
    "image_list = []\n",
    "\n",
    "for i in labels_concat.rsz_path:\n",
    "    # load image\n",
    "    img = io.imread(i).astype(np.float64)  \n",
    "    # append to list of all images\n",
    "    image_list.append(img)\n",
    "    \n",
    "# convert image list to single array\n",
    "X = np.array(image_list)\n",
    "y = labels_concat.is_bee\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to normalize our image data. Normalization is a general term that means changing the scale of our data so it is consistent.\n",
    "\n",
    "In this case, we want each feature to have a similar range so our neural network can learn effectively across all the features. As explained in the sklearn docs, \"If a feature has a variance that is orders of magnitude larger than others, it might dominate the objective function and make the estimator unable to learn from other features correctly as expected.\"\n",
    "\n",
    "We will scale our data so that it has a mean of 0 and standard deviation of 1. We'll use sklearn's StandardScaler to do the math for us, which entails taking each value, subtracting the mean, and then dividing by the standard deviation. We need to do this for each color channel (i.e. each feature) individually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split out evaluation sets (x_eval and y_eval)\n",
    "x_interim, x_eval, y_interim, y_eval = train_test_split(X,\n",
    "                                           y,\n",
    "                                           test_size=0.2,\n",
    "                                           random_state=52)\n",
    "\n",
    "# split remaining data into train and test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_interim,\n",
    "                                                   y_interim, \n",
    "                                                   test_size=0.4,\n",
    "                                                   random_state=52)\n",
    "\n",
    "# initialize standard scaler\n",
    "ss = StandardScaler()\n",
    "\n",
    "def scale_features(train_features, test_features):\n",
    "    for image in train_features:\n",
    "        # for each channel, apply standard scaler's fit_transform method\n",
    "        for channel in range(image.shape[2]):\n",
    "            image[:, :, channel] = ss.fit_transform(image[:, :, channel])\n",
    "    for image in test_features:\n",
    "        # for each channel, apply standard scaler's transform method\n",
    "        for channel in range(image.shape[2]):\n",
    "            image[:, :, channel] = ss.fit_transform(image[:, :, channel])\n",
    "\n",
    "# apply scale_features to four sets of features\n",
    "scale_features(x_interim, x_eval)\n",
    "scale_features(x_train, x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's time to start building our deep learning model, a convolutional neural network (CNN). CNNs are a specific kind of artificial neural network that is very effective for image classification because they are able to take into account the spatial coherence of the image, i.e., that pixels close to each other are often related.\n",
    "\n",
    "Building a CNN begins with specifying the model type. We'll use a Sequential model, which is a linear stack of layers. We'll then add two convolutional layers. To understand convolutional layers, imagine a flashlight being shown over the top left corner of the image and slowly sliding across all the areas of the image, moving across the image in the same way your eyes move across words on a page. Convolutional layers pass a kernel (a sliding window) over the image and perform element-wise matrix multiplication between the kernel values and the pixel values in the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set model constants\n",
    "num_classes = 1\n",
    "\n",
    "# define model as Sequential\n",
    "model = Sequential()\n",
    "\n",
    "# first convolutional layer with 32 filters\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(50, 50, 3)))\n",
    "model.add(BatchNormalization())\n",
    "# add a second 2D convolutional layer with 64 filters\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "#model.add(BatchNormalization())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll add the following layers:\n",
    "\n",
    "MaxPooling. This passes a (2, 2) moving window over the image and downscales the image by outputting the maximum value within the window.\n",
    "\n",
    "Conv2D. This adds a third convolutional layer since deeper models, i.e. models with more convolutional layers, are better able to learn features from images\n",
    "\n",
    "Dropout. This prevents the model from overfitting, i.e. perfectly remembering each image, by randomly setting 25% of the input units to 0 at each update during training.\n",
    "\n",
    "Flatten. As its name suggests, this flattens the output from the convolutional part of the CNN into a one-dimensional feature vector which can be passed into the following fully connected layers.\n",
    "\n",
    "Dense. Fully connected layer where every input is connected to every output (see image below).\n",
    "\n",
    "Dropout. Another dropout layer to safeguard against overfitting, this time with a rate of 50%.\n",
    "\n",
    "Dense. Final layer which calculates the probability the image is either a bumble bee or honey bee."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 48, 48, 32)        896       \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 48, 48, 32)       128       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 46, 46, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 23, 23, 64)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 21, 21, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 10, 10, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 8, 8, 256)         295168    \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 4, 4, 256)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 4, 4, 256)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 4096)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               524416    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " preds (Dense)               (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 913,089\n",
      "Trainable params: 913,025\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# reduce dimensionality through max pooling\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "# third convolutional layer with 64 filters\n",
    "model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
    "\n",
    "#model.add(BatchNormalization())\n",
    "# reduce dimensionality through max pooling\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "# forth convolutional layer with 256 filters\n",
    "model.add(Conv2D(256, kernel_size=(3, 3), activation='relu'))\n",
    "\n",
    "# reduce dimensionality through max pooling\n",
    "model.add(MaxPooling2D(pool_size=(2,2))) #the last change\n",
    "\n",
    "# add dropout to prevent over fitting\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# necessary flatten step preceeding dense layer\n",
    "model.add(Flatten())\n",
    "\n",
    "# fully connected layer\n",
    "model.add(Dense(128, activation='relu'))\n",
    "\n",
    "# add additional dropout to prevent overfitting\n",
    "model.add(Dropout(0.50))\n",
    "\n",
    "# prediction layers\n",
    "model.add(Dense(num_classes, activation='sigmoid', name='preds'))\n",
    "\n",
    "# show model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've specified the model architecture, we will compile the model for training. For this we need to specify the loss function (what we're trying to minimize), the optimizer (how we want to go about minimizing the loss), and the metric (how we'll judge the performance of the model).\n",
    "\n",
    "Then, we'll call .fit to begin the trainig the process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "30/30 [==============================] - 7s 229ms/step - loss: 0.7439 - accuracy: 0.5000 - val_loss: 0.6924 - val_accuracy: 0.5125\n",
      "Epoch 2/200\n",
      "30/30 [==============================] - 6s 218ms/step - loss: 0.7181 - accuracy: 0.5188 - val_loss: 0.6899 - val_accuracy: 0.5437\n",
      "Epoch 3/200\n",
      "30/30 [==============================] - 6s 210ms/step - loss: 0.7161 - accuracy: 0.5281 - val_loss: 0.6874 - val_accuracy: 0.5609\n",
      "Epoch 4/200\n",
      "30/30 [==============================] - 6s 207ms/step - loss: 0.7114 - accuracy: 0.5125 - val_loss: 0.6855 - val_accuracy: 0.5781\n",
      "Epoch 5/200\n",
      "30/30 [==============================] - 7s 225ms/step - loss: 0.6939 - accuracy: 0.5406 - val_loss: 0.6831 - val_accuracy: 0.6016\n",
      "Epoch 6/200\n",
      "30/30 [==============================] - 7s 222ms/step - loss: 0.6889 - accuracy: 0.5406 - val_loss: 0.6795 - val_accuracy: 0.6141\n",
      "Epoch 7/200\n",
      "30/30 [==============================] - 7s 223ms/step - loss: 0.6700 - accuracy: 0.5760 - val_loss: 0.6758 - val_accuracy: 0.6125\n",
      "Epoch 8/200\n",
      "30/30 [==============================] - 7s 233ms/step - loss: 0.6712 - accuracy: 0.5729 - val_loss: 0.6733 - val_accuracy: 0.6281\n",
      "Epoch 9/200\n",
      "30/30 [==============================] - 7s 244ms/step - loss: 0.6533 - accuracy: 0.6229 - val_loss: 0.6687 - val_accuracy: 0.6266\n",
      "Epoch 10/200\n",
      "30/30 [==============================] - 7s 233ms/step - loss: 0.6687 - accuracy: 0.5906 - val_loss: 0.6652 - val_accuracy: 0.6344\n",
      "Epoch 11/200\n",
      "30/30 [==============================] - 7s 235ms/step - loss: 0.6598 - accuracy: 0.5979 - val_loss: 0.6623 - val_accuracy: 0.6484\n",
      "Epoch 12/200\n",
      "30/30 [==============================] - 7s 246ms/step - loss: 0.6541 - accuracy: 0.6083 - val_loss: 0.6564 - val_accuracy: 0.6547\n",
      "Epoch 13/200\n",
      "30/30 [==============================] - 8s 253ms/step - loss: 0.6500 - accuracy: 0.6281 - val_loss: 0.6541 - val_accuracy: 0.6641\n",
      "Epoch 14/200\n",
      "30/30 [==============================] - 7s 240ms/step - loss: 0.6417 - accuracy: 0.6146 - val_loss: 0.6500 - val_accuracy: 0.6531\n",
      "Epoch 15/200\n",
      "30/30 [==============================] - 7s 234ms/step - loss: 0.6322 - accuracy: 0.6344 - val_loss: 0.6481 - val_accuracy: 0.6547\n",
      "Epoch 16/200\n",
      "30/30 [==============================] - 7s 231ms/step - loss: 0.6377 - accuracy: 0.6344 - val_loss: 0.6421 - val_accuracy: 0.6578\n",
      "Epoch 17/200\n",
      "30/30 [==============================] - 7s 235ms/step - loss: 0.6355 - accuracy: 0.6313 - val_loss: 0.6384 - val_accuracy: 0.6453\n",
      "Epoch 18/200\n",
      "30/30 [==============================] - 7s 233ms/step - loss: 0.6284 - accuracy: 0.6396 - val_loss: 0.6348 - val_accuracy: 0.6562\n",
      "Epoch 19/200\n",
      "30/30 [==============================] - 7s 231ms/step - loss: 0.6290 - accuracy: 0.6281 - val_loss: 0.6333 - val_accuracy: 0.6734\n",
      "Epoch 20/200\n",
      "30/30 [==============================] - 7s 234ms/step - loss: 0.6194 - accuracy: 0.6677 - val_loss: 0.6302 - val_accuracy: 0.6687\n",
      "Epoch 21/200\n",
      "30/30 [==============================] - 7s 232ms/step - loss: 0.6197 - accuracy: 0.6479 - val_loss: 0.6284 - val_accuracy: 0.6672\n",
      "Epoch 22/200\n",
      "30/30 [==============================] - 7s 230ms/step - loss: 0.6177 - accuracy: 0.6562 - val_loss: 0.6270 - val_accuracy: 0.6734\n",
      "Epoch 23/200\n",
      "30/30 [==============================] - 7s 238ms/step - loss: 0.6021 - accuracy: 0.6760 - val_loss: 0.6237 - val_accuracy: 0.6734\n",
      "Epoch 24/200\n",
      "30/30 [==============================] - 7s 233ms/step - loss: 0.6139 - accuracy: 0.6542 - val_loss: 0.6226 - val_accuracy: 0.6641\n",
      "Epoch 25/200\n",
      "30/30 [==============================] - 7s 236ms/step - loss: 0.6039 - accuracy: 0.6656 - val_loss: 0.6213 - val_accuracy: 0.6672\n",
      "Epoch 26/200\n",
      "30/30 [==============================] - 7s 232ms/step - loss: 0.6025 - accuracy: 0.6750 - val_loss: 0.6234 - val_accuracy: 0.6469\n",
      "Epoch 27/200\n",
      "30/30 [==============================] - 7s 235ms/step - loss: 0.5905 - accuracy: 0.6812 - val_loss: 0.6163 - val_accuracy: 0.6719\n",
      "Epoch 28/200\n",
      "30/30 [==============================] - 7s 233ms/step - loss: 0.5927 - accuracy: 0.6823 - val_loss: 0.6188 - val_accuracy: 0.6547\n",
      "Epoch 29/200\n",
      "30/30 [==============================] - 7s 245ms/step - loss: 0.5750 - accuracy: 0.6979 - val_loss: 0.6121 - val_accuracy: 0.6781\n",
      "Epoch 30/200\n",
      "30/30 [==============================] - 7s 242ms/step - loss: 0.5800 - accuracy: 0.7094 - val_loss: 0.6119 - val_accuracy: 0.6625\n",
      "Epoch 31/200\n",
      "30/30 [==============================] - 7s 234ms/step - loss: 0.5856 - accuracy: 0.6760 - val_loss: 0.6077 - val_accuracy: 0.6859\n",
      "Epoch 32/200\n",
      "30/30 [==============================] - 7s 235ms/step - loss: 0.5682 - accuracy: 0.7146 - val_loss: 0.6070 - val_accuracy: 0.6672\n",
      "Epoch 33/200\n",
      "30/30 [==============================] - 7s 240ms/step - loss: 0.5853 - accuracy: 0.6969 - val_loss: 0.6117 - val_accuracy: 0.6516\n",
      "Epoch 34/200\n",
      "30/30 [==============================] - 7s 244ms/step - loss: 0.5662 - accuracy: 0.7083 - val_loss: 0.6027 - val_accuracy: 0.6844\n",
      "Epoch 35/200\n",
      "30/30 [==============================] - 8s 259ms/step - loss: 0.5646 - accuracy: 0.7219 - val_loss: 0.6010 - val_accuracy: 0.6844\n",
      "Epoch 36/200\n",
      "30/30 [==============================] - 7s 249ms/step - loss: 0.5551 - accuracy: 0.7188 - val_loss: 0.6074 - val_accuracy: 0.6578\n",
      "Epoch 37/200\n",
      "30/30 [==============================] - 8s 255ms/step - loss: 0.5743 - accuracy: 0.7000 - val_loss: 0.6082 - val_accuracy: 0.6531\n",
      "Epoch 38/200\n",
      "30/30 [==============================] - 7s 247ms/step - loss: 0.5530 - accuracy: 0.7240 - val_loss: 0.5979 - val_accuracy: 0.6844\n",
      "Epoch 39/200\n",
      "30/30 [==============================] - 7s 227ms/step - loss: 0.5543 - accuracy: 0.7156 - val_loss: 0.5964 - val_accuracy: 0.6875\n",
      "Epoch 40/200\n",
      "30/30 [==============================] - 7s 228ms/step - loss: 0.5344 - accuracy: 0.7500 - val_loss: 0.5981 - val_accuracy: 0.6734\n",
      "Epoch 41/200\n",
      "30/30 [==============================] - 7s 229ms/step - loss: 0.5500 - accuracy: 0.7156 - val_loss: 0.5926 - val_accuracy: 0.7047\n",
      "Epoch 42/200\n",
      "30/30 [==============================] - 7s 228ms/step - loss: 0.5474 - accuracy: 0.7208 - val_loss: 0.5925 - val_accuracy: 0.6969\n",
      "Epoch 43/200\n",
      "30/30 [==============================] - 7s 231ms/step - loss: 0.5394 - accuracy: 0.7510 - val_loss: 0.5893 - val_accuracy: 0.7047\n",
      "Epoch 44/200\n",
      "30/30 [==============================] - 7s 229ms/step - loss: 0.5368 - accuracy: 0.7437 - val_loss: 0.5922 - val_accuracy: 0.6781\n",
      "Epoch 45/200\n",
      "30/30 [==============================] - 7s 230ms/step - loss: 0.5438 - accuracy: 0.7281 - val_loss: 0.5885 - val_accuracy: 0.6938\n",
      "Epoch 46/200\n",
      "30/30 [==============================] - 7s 230ms/step - loss: 0.5304 - accuracy: 0.7354 - val_loss: 0.5927 - val_accuracy: 0.6797\n",
      "Epoch 47/200\n",
      "30/30 [==============================] - 7s 246ms/step - loss: 0.5405 - accuracy: 0.7188 - val_loss: 0.5862 - val_accuracy: 0.6984\n",
      "Epoch 48/200\n",
      "30/30 [==============================] - 8s 252ms/step - loss: 0.5135 - accuracy: 0.7427 - val_loss: 0.5873 - val_accuracy: 0.6844\n",
      "Epoch 49/200\n",
      "30/30 [==============================] - 7s 246ms/step - loss: 0.5078 - accuracy: 0.7646 - val_loss: 0.5838 - val_accuracy: 0.7141\n",
      "Epoch 50/200\n",
      "30/30 [==============================] - 7s 241ms/step - loss: 0.5184 - accuracy: 0.7365 - val_loss: 0.5829 - val_accuracy: 0.7000\n",
      "Epoch 51/200\n",
      "30/30 [==============================] - 7s 236ms/step - loss: 0.5182 - accuracy: 0.7406 - val_loss: 0.5823 - val_accuracy: 0.7000\n",
      "Epoch 52/200\n",
      "30/30 [==============================] - 7s 226ms/step - loss: 0.5113 - accuracy: 0.7458 - val_loss: 0.5809 - val_accuracy: 0.7109\n",
      "Epoch 53/200\n",
      "30/30 [==============================] - 7s 228ms/step - loss: 0.4994 - accuracy: 0.7802 - val_loss: 0.5792 - val_accuracy: 0.7063\n",
      "Epoch 54/200\n",
      "30/30 [==============================] - 7s 227ms/step - loss: 0.5188 - accuracy: 0.7448 - val_loss: 0.5854 - val_accuracy: 0.6938\n",
      "Epoch 55/200\n",
      "30/30 [==============================] - 7s 226ms/step - loss: 0.5063 - accuracy: 0.7656 - val_loss: 0.5794 - val_accuracy: 0.7078\n",
      "Epoch 56/200\n",
      "30/30 [==============================] - 7s 226ms/step - loss: 0.4998 - accuracy: 0.7563 - val_loss: 0.5757 - val_accuracy: 0.7109\n",
      "Epoch 57/200\n",
      "30/30 [==============================] - 7s 229ms/step - loss: 0.5119 - accuracy: 0.7500 - val_loss: 0.5750 - val_accuracy: 0.7203\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/200\n",
      "30/30 [==============================] - 7s 229ms/step - loss: 0.5005 - accuracy: 0.7490 - val_loss: 0.5767 - val_accuracy: 0.7078\n",
      "Epoch 59/200\n",
      "30/30 [==============================] - 7s 229ms/step - loss: 0.4975 - accuracy: 0.7625 - val_loss: 0.5760 - val_accuracy: 0.7094\n",
      "Epoch 60/200\n",
      "30/30 [==============================] - 7s 243ms/step - loss: 0.5081 - accuracy: 0.7396 - val_loss: 0.5976 - val_accuracy: 0.6828\n",
      "Epoch 61/200\n",
      "30/30 [==============================] - 7s 232ms/step - loss: 0.4811 - accuracy: 0.7760 - val_loss: 0.5729 - val_accuracy: 0.7172\n",
      "Epoch 62/200\n",
      "30/30 [==============================] - 7s 227ms/step - loss: 0.4802 - accuracy: 0.7792 - val_loss: 0.5735 - val_accuracy: 0.7172\n",
      "Epoch 63/200\n",
      "30/30 [==============================] - 7s 227ms/step - loss: 0.4886 - accuracy: 0.7719 - val_loss: 0.5777 - val_accuracy: 0.7016\n",
      "Epoch 64/200\n",
      "30/30 [==============================] - 7s 226ms/step - loss: 0.4871 - accuracy: 0.7677 - val_loss: 0.5701 - val_accuracy: 0.7125\n",
      "Epoch 65/200\n",
      "30/30 [==============================] - 7s 226ms/step - loss: 0.4721 - accuracy: 0.7760 - val_loss: 0.5687 - val_accuracy: 0.7141\n",
      "Epoch 66/200\n",
      "30/30 [==============================] - 7s 227ms/step - loss: 0.4777 - accuracy: 0.7833 - val_loss: 0.5773 - val_accuracy: 0.7141\n",
      "Epoch 67/200\n",
      "30/30 [==============================] - 7s 231ms/step - loss: 0.4601 - accuracy: 0.7906 - val_loss: 0.5734 - val_accuracy: 0.7156\n",
      "Epoch 68/200\n",
      "30/30 [==============================] - 7s 228ms/step - loss: 0.4598 - accuracy: 0.7937 - val_loss: 0.5669 - val_accuracy: 0.7125\n",
      "Epoch 69/200\n",
      "30/30 [==============================] - 7s 228ms/step - loss: 0.4586 - accuracy: 0.7802 - val_loss: 0.5644 - val_accuracy: 0.7156\n",
      "Epoch 70/200\n",
      "30/30 [==============================] - 7s 231ms/step - loss: 0.4588 - accuracy: 0.7948 - val_loss: 0.5673 - val_accuracy: 0.7219\n",
      "Epoch 71/200\n",
      "30/30 [==============================] - 7s 230ms/step - loss: 0.4678 - accuracy: 0.7812 - val_loss: 0.5644 - val_accuracy: 0.7203\n",
      "Epoch 72/200\n",
      "30/30 [==============================] - 7s 227ms/step - loss: 0.4645 - accuracy: 0.7927 - val_loss: 0.5810 - val_accuracy: 0.7047\n",
      "Epoch 73/200\n",
      "30/30 [==============================] - 7s 227ms/step - loss: 0.4573 - accuracy: 0.7885 - val_loss: 0.5631 - val_accuracy: 0.7250\n",
      "Epoch 74/200\n",
      "30/30 [==============================] - 7s 228ms/step - loss: 0.4516 - accuracy: 0.7969 - val_loss: 0.5635 - val_accuracy: 0.7266\n",
      "Epoch 75/200\n",
      "30/30 [==============================] - 7s 228ms/step - loss: 0.4524 - accuracy: 0.8010 - val_loss: 0.5640 - val_accuracy: 0.7219\n",
      "Epoch 76/200\n",
      "30/30 [==============================] - 7s 228ms/step - loss: 0.4579 - accuracy: 0.7969 - val_loss: 0.5602 - val_accuracy: 0.7266\n",
      "Epoch 77/200\n",
      "30/30 [==============================] - 7s 229ms/step - loss: 0.4389 - accuracy: 0.8125 - val_loss: 0.5657 - val_accuracy: 0.7188\n",
      "Epoch 78/200\n",
      "30/30 [==============================] - 7s 227ms/step - loss: 0.4467 - accuracy: 0.7969 - val_loss: 0.5591 - val_accuracy: 0.7297\n",
      "Epoch 79/200\n",
      "30/30 [==============================] - 7s 227ms/step - loss: 0.4375 - accuracy: 0.8094 - val_loss: 0.5600 - val_accuracy: 0.7312\n",
      "Epoch 80/200\n",
      "30/30 [==============================] - 7s 230ms/step - loss: 0.4430 - accuracy: 0.8062 - val_loss: 0.5578 - val_accuracy: 0.7297\n",
      "Epoch 81/200\n",
      "30/30 [==============================] - 7s 229ms/step - loss: 0.4320 - accuracy: 0.8073 - val_loss: 0.5636 - val_accuracy: 0.7188\n",
      "Epoch 82/200\n",
      "30/30 [==============================] - 7s 228ms/step - loss: 0.4504 - accuracy: 0.7990 - val_loss: 0.5602 - val_accuracy: 0.7188\n",
      "Epoch 83/200\n",
      "30/30 [==============================] - 7s 227ms/step - loss: 0.4365 - accuracy: 0.8167 - val_loss: 0.5622 - val_accuracy: 0.7203\n",
      "Epoch 84/200\n",
      "30/30 [==============================] - 7s 228ms/step - loss: 0.4393 - accuracy: 0.8115 - val_loss: 0.5563 - val_accuracy: 0.7375\n",
      "Epoch 85/200\n",
      "30/30 [==============================] - 7s 226ms/step - loss: 0.4266 - accuracy: 0.8031 - val_loss: 0.5555 - val_accuracy: 0.7328\n",
      "Epoch 86/200\n",
      "30/30 [==============================] - 7s 233ms/step - loss: 0.4107 - accuracy: 0.8240 - val_loss: 0.5584 - val_accuracy: 0.7250\n",
      "Epoch 87/200\n",
      "30/30 [==============================] - 7s 240ms/step - loss: 0.4227 - accuracy: 0.8146 - val_loss: 0.5551 - val_accuracy: 0.7359\n",
      "Epoch 88/200\n",
      "30/30 [==============================] - 7s 236ms/step - loss: 0.4209 - accuracy: 0.8188 - val_loss: 0.5542 - val_accuracy: 0.7344\n",
      "Epoch 89/200\n",
      "30/30 [==============================] - 7s 228ms/step - loss: 0.4064 - accuracy: 0.8333 - val_loss: 0.5533 - val_accuracy: 0.7406\n",
      "Epoch 90/200\n",
      "30/30 [==============================] - 7s 228ms/step - loss: 0.4292 - accuracy: 0.8167 - val_loss: 0.5531 - val_accuracy: 0.7391\n",
      "Epoch 91/200\n",
      "30/30 [==============================] - 7s 228ms/step - loss: 0.4124 - accuracy: 0.8198 - val_loss: 0.5656 - val_accuracy: 0.7266\n",
      "Epoch 92/200\n",
      "30/30 [==============================] - 7s 227ms/step - loss: 0.3991 - accuracy: 0.8281 - val_loss: 0.5640 - val_accuracy: 0.7141\n",
      "Epoch 93/200\n",
      "30/30 [==============================] - 7s 228ms/step - loss: 0.4254 - accuracy: 0.8083 - val_loss: 0.5513 - val_accuracy: 0.7344\n",
      "Epoch 94/200\n",
      "30/30 [==============================] - 7s 235ms/step - loss: 0.3986 - accuracy: 0.8271 - val_loss: 0.5572 - val_accuracy: 0.7250\n",
      "Epoch 95/200\n",
      "30/30 [==============================] - 7s 232ms/step - loss: 0.4021 - accuracy: 0.8313 - val_loss: 0.5499 - val_accuracy: 0.7484\n",
      "Epoch 96/200\n",
      "30/30 [==============================] - 7s 239ms/step - loss: 0.3889 - accuracy: 0.8365 - val_loss: 0.5491 - val_accuracy: 0.7391\n",
      "Epoch 97/200\n",
      "30/30 [==============================] - 8s 251ms/step - loss: 0.4009 - accuracy: 0.8229 - val_loss: 0.5521 - val_accuracy: 0.7312\n",
      "Epoch 98/200\n",
      "30/30 [==============================] - 7s 237ms/step - loss: 0.3949 - accuracy: 0.8229 - val_loss: 0.5482 - val_accuracy: 0.7406\n",
      "Epoch 99/200\n",
      "30/30 [==============================] - 7s 245ms/step - loss: 0.4044 - accuracy: 0.8208 - val_loss: 0.5511 - val_accuracy: 0.7406\n",
      "Epoch 100/200\n",
      "30/30 [==============================] - 7s 240ms/step - loss: 0.3891 - accuracy: 0.8271 - val_loss: 0.5484 - val_accuracy: 0.7453\n",
      "Epoch 101/200\n",
      "30/30 [==============================] - 7s 234ms/step - loss: 0.4001 - accuracy: 0.8385 - val_loss: 0.5547 - val_accuracy: 0.7266\n",
      "Epoch 102/200\n",
      "30/30 [==============================] - 7s 242ms/step - loss: 0.3841 - accuracy: 0.8365 - val_loss: 0.5490 - val_accuracy: 0.7453\n",
      "Epoch 103/200\n",
      "30/30 [==============================] - 7s 240ms/step - loss: 0.3878 - accuracy: 0.8302 - val_loss: 0.5472 - val_accuracy: 0.7469\n",
      "Epoch 104/200\n",
      "30/30 [==============================] - 7s 231ms/step - loss: 0.3739 - accuracy: 0.8458 - val_loss: 0.5459 - val_accuracy: 0.7406\n",
      "Epoch 105/200\n",
      "30/30 [==============================] - 7s 232ms/step - loss: 0.3686 - accuracy: 0.8458 - val_loss: 0.5533 - val_accuracy: 0.7297\n",
      "Epoch 106/200\n",
      "30/30 [==============================] - 7s 236ms/step - loss: 0.3717 - accuracy: 0.8531 - val_loss: 0.5449 - val_accuracy: 0.7531\n",
      "Epoch 107/200\n",
      "30/30 [==============================] - 7s 246ms/step - loss: 0.3685 - accuracy: 0.8490 - val_loss: 0.5497 - val_accuracy: 0.7359\n",
      "Epoch 108/200\n",
      "30/30 [==============================] - 7s 243ms/step - loss: 0.3702 - accuracy: 0.8542 - val_loss: 0.5449 - val_accuracy: 0.7437\n",
      "Epoch 109/200\n",
      "30/30 [==============================] - 7s 239ms/step - loss: 0.3719 - accuracy: 0.8500 - val_loss: 0.5513 - val_accuracy: 0.7281\n",
      "Epoch 110/200\n",
      "30/30 [==============================] - 7s 237ms/step - loss: 0.3825 - accuracy: 0.8354 - val_loss: 0.5452 - val_accuracy: 0.7359\n",
      "Epoch 111/200\n",
      "30/30 [==============================] - 7s 237ms/step - loss: 0.3641 - accuracy: 0.8562 - val_loss: 0.5511 - val_accuracy: 0.7328\n",
      "Epoch 112/200\n",
      "30/30 [==============================] - 7s 241ms/step - loss: 0.3673 - accuracy: 0.8552 - val_loss: 0.5427 - val_accuracy: 0.7531\n",
      "Epoch 113/200\n",
      "30/30 [==============================] - 7s 240ms/step - loss: 0.3459 - accuracy: 0.8646 - val_loss: 0.5502 - val_accuracy: 0.7391\n",
      "Epoch 114/200\n",
      "30/30 [==============================] - 7s 242ms/step - loss: 0.3520 - accuracy: 0.8604 - val_loss: 0.5447 - val_accuracy: 0.7500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 115/200\n",
      "30/30 [==============================] - 7s 239ms/step - loss: 0.3724 - accuracy: 0.8458 - val_loss: 0.5413 - val_accuracy: 0.7469\n",
      "Epoch 116/200\n",
      "30/30 [==============================] - 7s 249ms/step - loss: 0.3599 - accuracy: 0.8458 - val_loss: 0.5434 - val_accuracy: 0.7516\n",
      "Epoch 117/200\n",
      "30/30 [==============================] - 8s 263ms/step - loss: 0.3416 - accuracy: 0.8781 - val_loss: 0.5424 - val_accuracy: 0.7516\n",
      "Epoch 118/200\n",
      "30/30 [==============================] - 7s 239ms/step - loss: 0.3513 - accuracy: 0.8594 - val_loss: 0.5464 - val_accuracy: 0.7453\n",
      "Epoch 119/200\n",
      "30/30 [==============================] - 7s 240ms/step - loss: 0.3379 - accuracy: 0.8656 - val_loss: 0.5442 - val_accuracy: 0.7453\n",
      "Epoch 120/200\n",
      "30/30 [==============================] - 7s 235ms/step - loss: 0.3537 - accuracy: 0.8687 - val_loss: 0.5409 - val_accuracy: 0.7500\n",
      "Epoch 121/200\n",
      "30/30 [==============================] - 7s 228ms/step - loss: 0.3484 - accuracy: 0.8594 - val_loss: 0.5466 - val_accuracy: 0.7359\n",
      "Epoch 122/200\n",
      "30/30 [==============================] - 7s 231ms/step - loss: 0.3403 - accuracy: 0.8667 - val_loss: 0.5422 - val_accuracy: 0.7437\n",
      "Epoch 123/200\n",
      "30/30 [==============================] - 7s 236ms/step - loss: 0.3323 - accuracy: 0.8813 - val_loss: 0.5778 - val_accuracy: 0.7250\n",
      "Epoch 124/200\n",
      "30/30 [==============================] - 7s 227ms/step - loss: 0.3286 - accuracy: 0.8740 - val_loss: 0.5551 - val_accuracy: 0.7188\n",
      "Epoch 125/200\n",
      "30/30 [==============================] - 7s 234ms/step - loss: 0.3237 - accuracy: 0.8729 - val_loss: 0.5409 - val_accuracy: 0.7500\n",
      "Epoch 126/200\n",
      "30/30 [==============================] - 7s 236ms/step - loss: 0.3351 - accuracy: 0.8781 - val_loss: 0.5478 - val_accuracy: 0.7375\n",
      "Epoch 127/200\n",
      "30/30 [==============================] - 7s 242ms/step - loss: 0.3313 - accuracy: 0.8729 - val_loss: 0.5444 - val_accuracy: 0.7391\n",
      "Epoch 128/200\n",
      "30/30 [==============================] - 7s 242ms/step - loss: 0.3230 - accuracy: 0.8729 - val_loss: 0.5604 - val_accuracy: 0.7188\n",
      "Epoch 129/200\n",
      "30/30 [==============================] - 8s 264ms/step - loss: 0.3312 - accuracy: 0.8677 - val_loss: 0.5402 - val_accuracy: 0.7563\n",
      "Epoch 130/200\n",
      "30/30 [==============================] - 8s 261ms/step - loss: 0.3203 - accuracy: 0.8708 - val_loss: 0.5737 - val_accuracy: 0.7312\n",
      "Epoch 131/200\n",
      "30/30 [==============================] - 7s 237ms/step - loss: 0.3152 - accuracy: 0.8844 - val_loss: 0.5400 - val_accuracy: 0.7453\n",
      "Epoch 132/200\n",
      "30/30 [==============================] - 7s 231ms/step - loss: 0.3091 - accuracy: 0.8938 - val_loss: 0.5402 - val_accuracy: 0.7516\n",
      "Epoch 133/200\n",
      "30/30 [==============================] - 7s 228ms/step - loss: 0.3176 - accuracy: 0.8740 - val_loss: 0.5376 - val_accuracy: 0.7469\n",
      "Epoch 134/200\n",
      "30/30 [==============================] - 7s 227ms/step - loss: 0.3059 - accuracy: 0.8844 - val_loss: 0.5388 - val_accuracy: 0.7500\n",
      "Epoch 135/200\n",
      "30/30 [==============================] - 7s 236ms/step - loss: 0.3092 - accuracy: 0.8833 - val_loss: 0.5389 - val_accuracy: 0.7500\n",
      "Epoch 136/200\n",
      "30/30 [==============================] - 7s 229ms/step - loss: 0.2861 - accuracy: 0.8958 - val_loss: 0.5758 - val_accuracy: 0.7281\n",
      "Epoch 137/200\n",
      "30/30 [==============================] - 7s 237ms/step - loss: 0.3196 - accuracy: 0.8729 - val_loss: 0.5472 - val_accuracy: 0.7484\n",
      "Epoch 138/200\n",
      "30/30 [==============================] - 7s 231ms/step - loss: 0.3073 - accuracy: 0.8833 - val_loss: 0.5411 - val_accuracy: 0.7531\n",
      "Epoch 139/200\n",
      "30/30 [==============================] - 7s 235ms/step - loss: 0.3054 - accuracy: 0.8927 - val_loss: 0.5475 - val_accuracy: 0.7484\n",
      "Epoch 140/200\n",
      "30/30 [==============================] - 7s 237ms/step - loss: 0.3055 - accuracy: 0.8667 - val_loss: 0.5453 - val_accuracy: 0.7359\n",
      "Epoch 141/200\n",
      "30/30 [==============================] - 7s 246ms/step - loss: 0.3010 - accuracy: 0.8833 - val_loss: 0.5485 - val_accuracy: 0.7437\n",
      "Epoch 142/200\n",
      "30/30 [==============================] - 8s 264ms/step - loss: 0.3013 - accuracy: 0.8781 - val_loss: 0.5460 - val_accuracy: 0.7391\n",
      "Epoch 143/200\n",
      "30/30 [==============================] - 7s 240ms/step - loss: 0.2949 - accuracy: 0.8885 - val_loss: 0.5374 - val_accuracy: 0.7516\n",
      "Epoch 144/200\n",
      "30/30 [==============================] - 7s 247ms/step - loss: 0.2853 - accuracy: 0.8927 - val_loss: 0.5570 - val_accuracy: 0.7437\n",
      "Epoch 145/200\n",
      "30/30 [==============================] - 7s 240ms/step - loss: 0.2931 - accuracy: 0.8854 - val_loss: 0.5356 - val_accuracy: 0.7500\n",
      "Epoch 146/200\n",
      "30/30 [==============================] - 7s 232ms/step - loss: 0.2819 - accuracy: 0.8917 - val_loss: 0.5458 - val_accuracy: 0.7516\n",
      "Epoch 147/200\n",
      "30/30 [==============================] - 7s 240ms/step - loss: 0.2718 - accuracy: 0.9031 - val_loss: 0.5396 - val_accuracy: 0.7531\n",
      "Epoch 148/200\n",
      "30/30 [==============================] - 8s 270ms/step - loss: 0.2851 - accuracy: 0.8979 - val_loss: 0.5399 - val_accuracy: 0.7531\n",
      "Epoch 149/200\n",
      "30/30 [==============================] - 8s 268ms/step - loss: 0.2785 - accuracy: 0.8990 - val_loss: 0.5424 - val_accuracy: 0.7391\n",
      "Epoch 150/200\n",
      "30/30 [==============================] - 7s 247ms/step - loss: 0.2779 - accuracy: 0.8927 - val_loss: 0.5357 - val_accuracy: 0.7437\n",
      "Epoch 151/200\n",
      "30/30 [==============================] - 7s 242ms/step - loss: 0.2915 - accuracy: 0.8917 - val_loss: 0.5368 - val_accuracy: 0.7500\n",
      "Epoch 152/200\n",
      "30/30 [==============================] - 7s 233ms/step - loss: 0.2811 - accuracy: 0.8948 - val_loss: 0.5483 - val_accuracy: 0.7469\n",
      "Epoch 153/200\n",
      "30/30 [==============================] - 7s 232ms/step - loss: 0.2673 - accuracy: 0.9062 - val_loss: 0.5511 - val_accuracy: 0.7500\n",
      "Epoch 154/200\n",
      "30/30 [==============================] - 7s 245ms/step - loss: 0.2863 - accuracy: 0.8938 - val_loss: 0.5621 - val_accuracy: 0.7219\n",
      "Epoch 155/200\n",
      "30/30 [==============================] - 8s 254ms/step - loss: 0.2849 - accuracy: 0.8938 - val_loss: 0.5329 - val_accuracy: 0.7531\n",
      "Epoch 156/200\n",
      "30/30 [==============================] - 7s 233ms/step - loss: 0.2743 - accuracy: 0.9000 - val_loss: 0.5407 - val_accuracy: 0.7469\n",
      "Epoch 157/200\n",
      "30/30 [==============================] - 8s 260ms/step - loss: 0.2632 - accuracy: 0.9104 - val_loss: 0.5355 - val_accuracy: 0.7422\n",
      "Epoch 158/200\n",
      "30/30 [==============================] - 7s 237ms/step - loss: 0.2640 - accuracy: 0.8979 - val_loss: 0.5357 - val_accuracy: 0.7453\n",
      "Epoch 159/200\n",
      "30/30 [==============================] - 7s 235ms/step - loss: 0.2513 - accuracy: 0.9135 - val_loss: 0.5354 - val_accuracy: 0.7469\n",
      "Epoch 160/200\n",
      "30/30 [==============================] - 7s 244ms/step - loss: 0.2583 - accuracy: 0.9115 - val_loss: 0.5378 - val_accuracy: 0.7453\n",
      "Epoch 161/200\n",
      "30/30 [==============================] - 7s 232ms/step - loss: 0.2527 - accuracy: 0.9125 - val_loss: 0.5384 - val_accuracy: 0.7453\n",
      "Epoch 162/200\n",
      "30/30 [==============================] - 7s 232ms/step - loss: 0.2545 - accuracy: 0.9021 - val_loss: 0.5345 - val_accuracy: 0.7484\n",
      "Epoch 163/200\n",
      "30/30 [==============================] - 7s 245ms/step - loss: 0.2557 - accuracy: 0.9146 - val_loss: 0.5310 - val_accuracy: 0.7453\n",
      "Epoch 164/200\n",
      "30/30 [==============================] - 8s 257ms/step - loss: 0.2567 - accuracy: 0.9031 - val_loss: 0.5330 - val_accuracy: 0.7563\n",
      "Epoch 165/200\n",
      "30/30 [==============================] - 7s 247ms/step - loss: 0.2374 - accuracy: 0.9177 - val_loss: 0.5527 - val_accuracy: 0.7531\n",
      "Epoch 166/200\n",
      "30/30 [==============================] - 7s 250ms/step - loss: 0.2426 - accuracy: 0.9187 - val_loss: 0.5442 - val_accuracy: 0.7547\n",
      "Epoch 167/200\n",
      "30/30 [==============================] - 7s 242ms/step - loss: 0.2411 - accuracy: 0.9198 - val_loss: 0.5547 - val_accuracy: 0.7484\n",
      "Epoch 168/200\n",
      "30/30 [==============================] - 7s 233ms/step - loss: 0.2399 - accuracy: 0.9073 - val_loss: 0.5418 - val_accuracy: 0.7500\n",
      "Epoch 169/200\n",
      "30/30 [==============================] - 8s 254ms/step - loss: 0.2361 - accuracy: 0.9271 - val_loss: 0.5375 - val_accuracy: 0.7484\n",
      "Epoch 170/200\n",
      "30/30 [==============================] - 8s 261ms/step - loss: 0.2424 - accuracy: 0.9187 - val_loss: 0.5453 - val_accuracy: 0.7453\n",
      "Epoch 171/200\n",
      "30/30 [==============================] - 7s 234ms/step - loss: 0.2272 - accuracy: 0.9260 - val_loss: 0.5460 - val_accuracy: 0.7516\n",
      "Epoch 172/200\n",
      "30/30 [==============================] - 7s 235ms/step - loss: 0.2335 - accuracy: 0.9219 - val_loss: 0.5443 - val_accuracy: 0.7500\n",
      "Epoch 173/200\n",
      "30/30 [==============================] - 7s 240ms/step - loss: 0.2266 - accuracy: 0.9240 - val_loss: 0.5437 - val_accuracy: 0.7594\n"
     ]
    }
   ],
   "source": [
    "#stopper for keras to monitor val_loss increasing\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
    "\n",
    "model.compile(\n",
    "    # set the loss as binary_crossentropy\n",
    "    loss=keras.losses.binary_crossentropy,\n",
    "    # set the optimizer as stochastic gradient descent\n",
    "    optimizer=keras.optimizers.SGD(learning_rate=0.001),\n",
    "    # set the metric as accuracy\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "my_model = model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    epochs=200,\n",
    "    verbose=1,\n",
    "    validation_data=(x_test, y_test),\n",
    "    # set stopper\n",
    "    callbacks=[callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to scoring the final iteration of the pre-trained model as we just did, we can also see the evolution of scores throughout training thanks to the History object. We'll use the pickle library to load the model history and then plot it.\n",
    "\n",
    "Notice how the accuracy improves over time, eventually leveling off. Correspondingly, the loss decreases over time. Plots like these can help diagnose overfitting. If we had seen an upward curve in the validation loss as times goes on (a U shape in the plot), we'd suspect that the model was starting to memorize the test set and would not generalize well to new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Extract the history from the training object\n",
    "history = my_model.history\n",
    "\n",
    "# Plot the training loss \n",
    "plt.plot(history['loss'], label='train_loss', color = 'blue')\n",
    "# Plot the validation loss\n",
    "plt.plot(history['val_loss'], label='validation_loss', color = 'green')\n",
    "\n",
    "# Show the figure\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use the evaluate method to see how well the model did at classifying bumble bees and honey bees for the test and validation sets. Recall that accuracy is the number of correct predictions divided by the total number of predictions. Given that our classes are balanced, a model that predicts 1.0 for every image would get an accuracy around 0.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the training accuracy\n",
    "plt.plot(history['accuracy'], label='accuracy', color = 'blue')\n",
    "# Plot the validation accyracy\n",
    "plt.plot(history['val_accuracy'], label='validation_accuracy', color = 'green')\n",
    "\n",
    "# Show the figure\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to scoring the final iteration of the pre-trained model as we just did, we can also see the evolution of scores throughout training thanks to the History object. We'll use the pickle library to load the model history and then plot it.\n",
    "\n",
    "Notice how the accuracy improves over time, eventually leveling off. Correspondingly, the loss decreases over time. Plots like these can help diagnose overfitting. If we had seen an upward curve in the validation loss as times goes on (a U shape in the plot), we'd suspect that the model was starting to memorize the test set and would not generalize well to new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.5436950922012329\n",
      "Test accuracy: 0.7593749761581421\n",
      "\n",
      "Eval loss: 0.5544189214706421\n",
      "Eval accuracy: 0.7174999713897705\n"
     ]
    }
   ],
   "source": [
    "# load pre-trained model\n",
    "pretrained_cnn = model\n",
    "\n",
    "# evaluate model on test set\n",
    "score = pretrained_cnn.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "print(\"\")\n",
    "\n",
    "# evaluate model on holdout set\n",
    "eval_score = pretrained_cnn.evaluate(x_eval, y_eval, verbose=0)\n",
    "# print loss score\n",
    "print('Eval loss:', eval_score[0])\n",
    "# print accuracy score\n",
    "print('Eval accuracy:', eval_score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 1s 45ms/step\n",
      "First five probabilities:\n",
      "[[0.9708726 ]\n",
      " [0.9718018 ]\n",
      " [0.28622207]\n",
      " [0.00173378]\n",
      " [0.52475685]]\n",
      "\n",
      "First five class predictions:\n",
      "[[1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]]\n",
      "\n",
      "bumble bee\n",
      "bumble bee\n",
      "honey bee\n",
      "honey bee\n",
      "bumble bee\n",
      "honey bee\n",
      "honey bee\n",
      "honey bee\n",
      "bumble bee\n",
      "honey bee\n",
      "bumble bee\n",
      "honey bee\n",
      "honey bee\n",
      "bumble bee\n",
      "honey bee\n",
      "honey bee\n",
      "honey bee\n",
      "bumble bee\n",
      "honey bee\n",
      "bumble bee\n",
      "bumble bee\n",
      "honey bee\n",
      "honey bee\n",
      "honey bee\n",
      "honey bee\n",
      "honey bee\n",
      "honey bee\n",
      "honey bee\n",
      "honey bee\n",
      "bumble bee\n",
      "bumble bee\n",
      "honey bee\n",
      "honey bee\n",
      "honey bee\n",
      "honey bee\n",
      "bumble bee\n",
      "bumble bee\n",
      "honey bee\n",
      "honey bee\n",
      "honey bee\n",
      "bumble bee\n",
      "bumble bee\n",
      "honey bee\n",
      "bumble bee\n",
      "honey bee\n",
      "honey bee\n",
      "bumble bee\n",
      "bumble bee\n",
      "bumble bee\n",
      "honey bee\n",
      "honey bee\n",
      "bumble bee\n",
      "bumble bee\n",
      "honey bee\n",
      "bumble bee\n",
      "bumble bee\n",
      "honey bee\n",
      "honey bee\n",
      "honey bee\n",
      "bumble bee\n",
      "bumble bee\n",
      "bumble bee\n",
      "bumble bee\n",
      "bumble bee\n",
      "honey bee\n",
      "honey bee\n",
      "bumble bee\n",
      "honey bee\n",
      "honey bee\n",
      "honey bee\n",
      "honey bee\n",
      "bumble bee\n",
      "honey bee\n",
      "honey bee\n",
      "bumble bee\n",
      "honey bee\n",
      "honey bee\n",
      "bumble bee\n",
      "bumble bee\n",
      "honey bee\n",
      "bumble bee\n",
      "honey bee\n",
      "bumble bee\n",
      "honey bee\n",
      "honey bee\n",
      "honey bee\n",
      "bumble bee\n",
      "honey bee\n",
      "honey bee\n",
      "honey bee\n",
      "bumble bee\n",
      "honey bee\n",
      "honey bee\n",
      "honey bee\n",
      "bumble bee\n",
      "honey bee\n",
      "bumble bee\n",
      "bumble bee\n",
      "bumble bee\n",
      "bumble bee\n",
      "honey bee\n",
      "bumble bee\n",
      "honey bee\n",
      "bumble bee\n",
      "bumble bee\n",
      "bumble bee\n",
      "honey bee\n",
      "bumble bee\n",
      "honey bee\n",
      "honey bee\n",
      "honey bee\n",
      "honey bee\n",
      "honey bee\n",
      "bumble bee\n",
      "honey bee\n",
      "honey bee\n",
      "honey bee\n",
      "bumble bee\n",
      "honey bee\n",
      "honey bee\n",
      "bumble bee\n",
      "honey bee\n",
      "honey bee\n",
      "honey bee\n",
      "bumble bee\n",
      "bumble bee\n",
      "bumble bee\n",
      "honey bee\n",
      "honey bee\n",
      "bumble bee\n",
      "honey bee\n",
      "bumble bee\n",
      "bumble bee\n",
      "honey bee\n",
      "honey bee\n",
      "honey bee\n",
      "honey bee\n",
      "bumble bee\n",
      "honey bee\n",
      "honey bee\n",
      "honey bee\n",
      "bumble bee\n",
      "bumble bee\n",
      "honey bee\n",
      "bumble bee\n",
      "bumble bee\n",
      "honey bee\n",
      "bumble bee\n",
      "bumble bee\n",
      "honey bee\n",
      "honey bee\n",
      "bumble bee\n",
      "honey bee\n",
      "honey bee\n",
      "bumble bee\n",
      "honey bee\n",
      "bumble bee\n",
      "honey bee\n",
      "bumble bee\n",
      "bumble bee\n",
      "bumble bee\n",
      "honey bee\n",
      "bumble bee\n",
      "honey bee\n",
      "honey bee\n",
      "bumble bee\n",
      "honey bee\n",
      "honey bee\n",
      "honey bee\n",
      "honey bee\n",
      "honey bee\n",
      "honey bee\n",
      "honey bee\n",
      "honey bee\n",
      "bumble bee\n",
      "bumble bee\n",
      "bumble bee\n",
      "honey bee\n",
      "honey bee\n",
      "honey bee\n",
      "bumble bee\n",
      "bumble bee\n",
      "bumble bee\n",
      "bumble bee\n",
      "bumble bee\n",
      "honey bee\n",
      "honey bee\n",
      "bumble bee\n",
      "bumble bee\n",
      "honey bee\n",
      "bumble bee\n",
      "honey bee\n",
      "honey bee\n",
      "honey bee\n",
      "bumble bee\n",
      "honey bee\n",
      "bumble bee\n",
      "honey bee\n",
      "bumble bee\n",
      "bumble bee\n",
      "bumble bee\n",
      "bumble bee\n",
      "honey bee\n",
      "bumble bee\n",
      "honey bee\n",
      "honey bee\n",
      "bumble bee\n",
      "bumble bee\n",
      "honey bee\n",
      "honey bee\n",
      "bumble bee\n",
      "honey bee\n",
      "honey bee\n",
      "bumble bee\n",
      "bumble bee\n",
      "bumble bee\n",
      "bumble bee\n",
      "honey bee\n",
      "bumble bee\n",
      "honey bee\n",
      "honey bee\n",
      "bumble bee\n",
      "honey bee\n",
      "bumble bee\n",
      "honey bee\n",
      "honey bee\n",
      "bumble bee\n",
      "honey bee\n",
      "honey bee\n",
      "honey bee\n",
      "bumble bee\n",
      "bumble bee\n",
      "honey bee\n",
      "honey bee\n",
      "bumble bee\n",
      "bumble bee\n",
      "bumble bee\n",
      "honey bee\n",
      "honey bee\n",
      "bumble bee\n",
      "bumble bee\n",
      "honey bee\n",
      "honey bee\n",
      "bumble bee\n",
      "honey bee\n",
      "honey bee\n",
      "bumble bee\n",
      "bumble bee\n",
      "honey bee\n",
      "honey bee\n",
      "honey bee\n",
      "bumble bee\n",
      "bumble bee\n",
      "honey bee\n",
      "bumble bee\n",
      "honey bee\n",
      "honey bee\n",
      "honey bee\n",
      "honey bee\n",
      "bumble bee\n",
      "honey bee\n",
      "honey bee\n",
      "honey bee\n",
      "honey bee\n",
      "bumble bee\n",
      "honey bee\n",
      "honey bee\n",
      "honey bee\n",
      "honey bee\n",
      "bumble bee\n",
      "bumble bee\n",
      "bumble bee\n",
      "honey bee\n",
      "honey bee\n",
      "honey bee\n",
      "bumble bee\n",
      "honey bee\n",
      "bumble bee\n",
      "honey bee\n",
      "honey bee\n",
      "bumble bee\n",
      "honey bee\n",
      "bumble bee\n",
      "honey bee\n",
      "honey bee\n",
      "honey bee\n",
      "honey bee\n",
      "bumble bee\n",
      "bumble bee\n",
      "honey bee\n",
      "honey bee\n",
      "bumble bee\n",
      "honey bee\n",
      "bumble bee\n",
      "honey bee\n",
      "honey bee\n",
      "honey bee\n",
      "honey bee\n",
      "honey bee\n",
      "honey bee\n",
      "honey bee\n",
      "honey bee\n",
      "bumble bee\n",
      "bumble bee\n",
      "honey bee\n",
      "honey bee\n",
      "bumble bee\n",
      "honey bee\n",
      "bumble bee\n",
      "bumble bee\n",
      "honey bee\n",
      "bumble bee\n",
      "honey bee\n",
      "bumble bee\n",
      "honey bee\n",
      "bumble bee\n",
      "bumble bee\n",
      "honey bee\n",
      "honey bee\n",
      "honey bee\n",
      "honey bee\n",
      "bumble bee\n",
      "honey bee\n",
      "honey bee\n",
      "honey bee\n",
      "honey bee\n",
      "honey bee\n",
      "bumble bee\n",
      "bumble bee\n",
      "bumble bee\n",
      "honey bee\n",
      "bumble bee\n",
      "bumble bee\n",
      "bumble bee\n",
      "honey bee\n",
      "honey bee\n",
      "bumble bee\n",
      "honey bee\n",
      "honey bee\n",
      "honey bee\n",
      "honey bee\n",
      "bumble bee\n",
      "bumble bee\n",
      "bumble bee\n",
      "bumble bee\n",
      "honey bee\n",
      "honey bee\n",
      "bumble bee\n",
      "bumble bee\n",
      "honey bee\n",
      "honey bee\n",
      "bumble bee\n",
      "bumble bee\n",
      "honey bee\n",
      "honey bee\n",
      "honey bee\n",
      "honey bee\n",
      "honey bee\n",
      "honey bee\n",
      "honey bee\n",
      "honey bee\n",
      "honey bee\n",
      "bumble bee\n",
      "honey bee\n",
      "bumble bee\n",
      "honey bee\n",
      "honey bee\n",
      "honey bee\n",
      "honey bee\n",
      "honey bee\n",
      "honey bee\n",
      "bumble bee\n",
      "honey bee\n",
      "honey bee\n",
      "honey bee\n",
      "bumble bee\n",
      "bumble bee\n",
      "honey bee\n",
      "honey bee\n",
      "bumble bee\n",
      "honey bee\n",
      "honey bee\n",
      "bumble bee\n",
      "honey bee\n",
      "honey bee\n",
      "bumble bee\n",
      "bumble bee\n",
      "honey bee\n",
      "bumble bee\n",
      "honey bee\n",
      "bumble bee\n",
      "bumble bee\n",
      "honey bee\n",
      "honey bee\n",
      "bumble bee\n",
      "bumble bee\n",
      "honey bee\n",
      "bumble bee\n",
      "bumble bee\n",
      "bumble bee\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predicted probabilities for x_eval\n",
    "y_proba = pretrained_cnn.predict(x_eval)\n",
    "\n",
    "print(\"First five probabilities:\")\n",
    "print(y_proba[:5])\n",
    "print(\"\")\n",
    "\n",
    "# predicted classes for x_eval\n",
    "y_pred = np.round(y_proba).astype('int')\n",
    "\n",
    "print(\"First five class predictions:\")\n",
    "print(y_pred[:5])\n",
    "print(\"\")\n",
    "\n",
    "#[f(x) if condition else g(x) for x in sequence]\n",
    "\n",
    "[print('bumble bee') if i == 1 else print('honey bee') for i in y_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
